{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.data import DataBlock\n",
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=aug_transforms(size=224,min_scale=0.75),\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- BASELINE --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.636237    2.114159    0.454070  4:09:37                                           \n",
      "1         1.252930    1.402056    0.558252  1:15:53                                          \n",
      "2         0.959257    1.068307    0.677745  1:49:34                                          \n",
      "3         0.732410    0.760982    0.759895  13:54:36                                           \n",
      "4         0.587539    0.550948    0.821509  1:04:46                                        \n"
     ]
    }
   ],
   "source": [
    "from fastai.losses import CrossEntropyLossFlat\n",
    "\n",
    "\n",
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(\n",
    "    dls, \n",
    "    model, \n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy\n",
    ")\n",
    "\n",
    "# @audit-ok : 5 epoch is + 6 hours!  FIX THIS SOMEHOW!\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- NORMALIZATION --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([0.4669, 0.4457, 0.4136]), TensorImage([0.2971, 0.2916, 0.3091]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_batch() method retrieves a single batch from the DataLoader\n",
    "# returned batch consists of a tuple, where\n",
    "# - (x) is a batch of input data\n",
    "# - (y) is a batch of labels\n",
    "x,y = dls.one_batch()\n",
    "\n",
    "# Computing the mean and standard deviation of the input data (x)\n",
    "# Specifying dim=[0,2,3], you're asking PyTorch to compute the mean and standard  \n",
    "# deviation across : \n",
    "# - batch, height, and width dimensions\n",
    "# - separately for each color channel\n",
    "# This will result in a mean and standard deviation for each color channel of  \n",
    "# the images in the batch.\n",
    "x.mean(dim=[0,2,3]), x.std(dim=[0,2,3])\n",
    "\n",
    "# (TensorImage([0.4669, 0.4457, 0.4136]), TensorImage([0.2971, 0.2916, 0.3091]))\n",
    "\n",
    "# Explain this result ^\n",
    "# MEAN VALUE : on average, \n",
    "# - the red channel has a value of 0.4669, \n",
    "# - the green channel a value of 0.4457, and \n",
    "# - the blue channel a value of 0.4136.\n",
    "# STANDARD DEVIATION :\n",
    "# - the red channel has a standard deviation of 0.2971,\n",
    "# - the green channel a standard deviation of 0.2916, and\n",
    "# - the blue channel a standard deviation of 0.3091.\n",
    "\n",
    "# These statistics can give you some insight into the characteristics of your  \n",
    "# image dataset. \n",
    "# For example, if the means are very different between channels, \n",
    "# - that might indicate that certain colors are more dominant in your images. \n",
    "# Similarly, a high standard deviation means \n",
    "# - that the values vary a lot from the mean, \n",
    "# - while a low standard deviation means that the values are generally close to \n",
    "# the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([-0.1231, -0.0449,  0.0777]),\n",
       " TensorImage([1.1290, 1.1470, 1.2299]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dls(batch_size, resolution):\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_items=get_image_files,\n",
    "        get_y=parent_label,\n",
    "        item_tfms=Resize(460),\n",
    "        batch_tfms=[\n",
    "            *aug_transforms(size=resolution, min_scale=0.75),\n",
    "            Normalize.from_stats(*imagenet_stats)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return dblock.dataloaders(path, batch_size=batch_size)\n",
    "\n",
    "dls = get_dls(64, 224)\n",
    "x,y = dls.one_batch()\n",
    "x.mean(dim=[0,2,3]), x.std(dim=[0,2,3])\n",
    "\n",
    "# (TensorImage([-0.1231, -0.0449,  0.0777]), TensorImage([1.1290, 1.1470, 1.2299]))\n",
    "# Explain what happened after normalization\n",
    "\n",
    "# After normalization, you get (TensorImage([-0.1231, -0.0449,  0.0777]), \n",
    "# TensorImage([1.1290, 1.1470, 1.2299])). The goal of normalization is to \n",
    "# adjust the values of an array so they share a common scale, without \n",
    "# distorting differences in the ranges of values or losing information. \n",
    "# In machine learning, normalization is a common step as it can make training \n",
    "# less sensitive to the scale of features, so we can better solve for \n",
    "# coefficients.\n",
    "\n",
    "# In this case, the normalization process has adjusted the mean and standard \n",
    "# deviation of your images. The new means are close to 0, and the new standard \n",
    "# deviations are close to 1. This is typically the goal of normalization in a \n",
    "# machine learning context: to shift the distribution of each feature to have a \n",
    "# mean of 0 and a standard deviation of 1. This helps to ensure that all \n",
    "# features have the same scale and the model does not become biased or overly \n",
    "# sensitive to features with larger scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.663105    2.947168    0.370052  2:50:35                                          \n",
      "1         1.251406    1.662431    0.453697  1:11:42                                          \n",
      "2         0.947334    0.836982    0.738984  58:35                                          \n",
      "3         0.740129    0.654092    0.799104  1:01:49                                        \n",
      "4         0.607023    0.568175    0.824496  56:57                                          \n"
     ]
    }
   ],
   "source": [
    "model = xresnet50()\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy\n",
    ")\n",
    "\n",
    "# @audit-ok : 5 epoch is + 6 hours!  FIX THIS SOMEHOW!\n",
    "learn.fit_one_cycle(5, 3e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         2.192905    4.081844    0.252427  06:01                                          \n",
      "1         1.530551    1.461747    0.522405  04:42                                          \n",
      "2         1.210109    1.178366    0.629574  04:45                                          \n",
      "3         1.161046    1.072473    0.663928  04:42                                          \n"
     ]
    }
   ],
   "source": [
    "# Training at a much lower resolution than 224 x 224\n",
    "dls = get_dls(12, 32) # @audit why batch size 128 instead of 64?\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    xresnet50(n_out=dls.c), # @audit ... explain?\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy\n",
    ")\n",
    "\n",
    "# @audit : Why are we only doing 4 instead of 5 epochs?\n",
    "# - Is it because the smaller resolution is for more basic features?\n",
    "# - And epoch 5 is for label correlated features?\n",
    "learn.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.098922    1.004947    0.684839  08:00                                          \n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         0.941069    0.900726    0.706497  07:56                                          \n",
      "1         0.956869    0.816833    0.733010  07:10                                          \n",
      "2         0.932111    0.747074    0.761016  06:25                                          \n",
      "3         0.830758    0.703328    0.768484  06:14                                          \n",
      "4         0.787315    0.680215    0.778566  06:15                                          \n"
     ]
    }
   ],
   "source": [
    "learn.dls = get_dls(12, 64)\n",
    "\n",
    "# fine tuning only the last epoch 5\n",
    "# - effectively freezing the first 4 epochs\n",
    "# - prevents forgetting the earlier base features\n",
    "learn.fine_tune(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7785661220550537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, targs = learn.get_preds()\n",
    "accuracy(preds, targs).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785661220550537"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, targs).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "Epoch 1/4 :                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7979835867881775"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tta, targs_tta = learn.tta()\n",
    "accuracy(preds_tta, targs_tta).item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- MIXUP --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup manual code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         2.305844    2.109548    0.328977  04:44                                          \n",
      "1         1.787737    1.607176    0.491038  04:47                                          \n",
      "2         1.668271    1.575980    0.522031  04:42                                          \n",
      "3         1.525355    1.190362    0.623973  52:01                                           \n",
      "4         1.440893    1.248785    0.616878  05:58                                          \n"
     ]
    }
   ],
   "source": [
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy,\n",
    "    cbs=MixUp\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- LABEL SMOOTHING --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         2.143363    1.892292    0.442494  04:50                                          \n",
      "1         1.658357    1.875266    0.495146  04:44                                          \n",
      "2         1.560091    1.522520    0.582898  04:42                                          \n",
      "3         1.394092    1.287970    0.679238  04:41                                          \n",
      "4         1.335982    1.292297    0.692681  04:42                                          \n"
     ]
    }
   ],
   "source": [
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=LabelSmoothingCrossEntropyFlat(),\n",
    "    metrics=accuracy\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
