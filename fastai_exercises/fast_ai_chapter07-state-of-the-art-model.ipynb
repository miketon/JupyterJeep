{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████| 100.00% [1557168128/1557161267 20:52<00:00]\r"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.data import DataBlock\n",
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=aug_transforms(size=224,min_scale=0.75),\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- BASELINE --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         1.636237    2.114159    0.454070  4:09:37                                           \n",
      "1         1.252930    1.402056    0.558252  1:15:53                                          \n",
      "2         0.959257    1.068307    0.677745  1:49:34                                          \n",
      "3         0.732410    0.760982    0.759895  13:54:36                                           \n",
      "4         0.587539    0.550948    0.821509  1:04:46                                        \n"
     ]
    }
   ],
   "source": [
    "from fastai.losses import CrossEntropyLossFlat\n",
    "\n",
    "\n",
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(\n",
    "    dls, \n",
    "    model, \n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy\n",
    ")\n",
    "\n",
    "# @audit-ok : 5 epoch is + 6 hours!  FIX THIS SOMEHOW!\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- NORMALIZATION --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([0.4669, 0.4457, 0.4136]), TensorImage([0.2971, 0.2916, 0.3091]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_batch() method retrieves a single batch from the DataLoader\n",
    "# returned batch consists of a tuple, where\n",
    "# - (x) is a batch of input data\n",
    "# - (y) is a batch of labels\n",
    "x,y = dls.one_batch()\n",
    "\n",
    "# Computing the mean and standard deviation of the input data (x)\n",
    "# Specifying dim=[0,2,3], you're asking PyTorch to compute the mean and standard  \n",
    "# deviation across : \n",
    "# - batch, height, and width dimensions\n",
    "# - separately for each color channel\n",
    "# This will result in a mean and standard deviation for each color channel of  \n",
    "# the images in the batch.\n",
    "x.mean(dim=[0,2,3]), x.std(dim=[0,2,3])\n",
    "\n",
    "# (TensorImage([0.4669, 0.4457, 0.4136]), TensorImage([0.2971, 0.2916, 0.3091]))\n",
    "\n",
    "# Explain this result ^\n",
    "# MEAN VALUE : on average, \n",
    "# - the red channel has a value of 0.4669, \n",
    "# - the green channel a value of 0.4457, and \n",
    "# - the blue channel a value of 0.4136.\n",
    "# STANDARD DEVIATION :\n",
    "# - the red channel has a standard deviation of 0.2971,\n",
    "# - the green channel a standard deviation of 0.2916, and\n",
    "# - the blue channel a standard deviation of 0.3091.\n",
    "\n",
    "# These statistics can give you some insight into the characteristics of your  \n",
    "# image dataset. \n",
    "# For example, if the means are very different between channels, \n",
    "# - that might indicate that certain colors are more dominant in your images. \n",
    "# Similarly, a high standard deviation means \n",
    "# - that the values vary a lot from the mean, \n",
    "# - while a low standard deviation means that the values are generally close to \n",
    "# the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([-0.1231, -0.0449,  0.0777]),\n",
       " TensorImage([1.1290, 1.1470, 1.2299]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dls(batch_size, resolution):\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_items=get_image_files,\n",
    "        get_y=parent_label,\n",
    "        item_tfms=Resize(460),\n",
    "        batch_tfms=[\n",
    "            *aug_transforms(size=resolution, min_scale=0.75),\n",
    "            Normalize.from_stats(*imagenet_stats)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return dblock.dataloaders(path, batch_size=batch_size)\n",
    "\n",
    "dls = get_dls(64, 224)\n",
    "x,y = dls.one_batch()\n",
    "x.mean(dim=[0,2,3]), x.std(dim=[0,2,3])\n",
    "\n",
    "# (TensorImage([-0.1231, -0.0449,  0.0777]), TensorImage([1.1290, 1.1470, 1.2299]))\n",
    "# Explain what happened after normalization\n",
    "\n",
    "# After normalization, you get (TensorImage([-0.1231, -0.0449,  0.0777]), \n",
    "# TensorImage([1.1290, 1.1470, 1.2299])). The goal of normalization is to \n",
    "# adjust the values of an array so they share a common scale, without \n",
    "# distorting differences in the ranges of values or losing information. \n",
    "# In machine learning, normalization is a common step as it can make training \n",
    "# less sensitive to the scale of features, so we can better solve for \n",
    "# coefficients.\n",
    "\n",
    "# In this case, the normalization process has adjusted the mean and standard \n",
    "# deviation of your images. The new means are close to 0, and the new standard \n",
    "# deviations are close to 1. This is typically the goal of normalization in a \n",
    "# machine learning context: to shift the distribution of each feature to have a \n",
    "# mean of 0 and a standard deviation of 1. This helps to ensure that all \n",
    "# features have the same scale and the model does not become biased or overly \n",
    "# sensitive to features with larger scales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
