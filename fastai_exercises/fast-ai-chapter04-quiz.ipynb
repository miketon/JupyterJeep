{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FASTAI CHAPTER 04 - QUIZ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How is a grayscale image represented on a computer? How is a color image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray scale image = 1 channel of 2D array of pixels with values from 0 to 255\n",
    "# Color image = 3 channels of 2D array of pixels with values from 0 to 255, one\n",
    "# channel for each of the RGB colors\n",
    "# Though unused here, common color image can include a 4th channel for alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) How are the files and folders in the MNIST_SAMPLE dataset structured? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The files and folders of the MNIST_SAMPLE dataset are stored in the following\n",
    "# folder structure:\n",
    "#   data/mnist_sample/\n",
    "#     # with 3 and 7 subfolders in the train and valid folders\n",
    "#     train/ # training set\n",
    "#     valid/ # validation set\n",
    "#     labels.csv # labels for the training and validation sets\n",
    "#                # where 0 == 3 and 1 == 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain how the \"pixel similarity\" approach to classifying digits works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"pixel similarity\" approach to classifying digits is to :\n",
    "# 1. Accumulate the pixel values for each digit class\n",
    "# 2. Divide the accumulated pixel values by the number of images in the class\n",
    "# 3. The resulting \"average digit\" will have blurry edges representing uncertainty\n",
    "# 4. For each image, calculate the DISTANCE between this image and the \"average digit\"\n",
    "# 5. Unfortunately this can only distinguish between 3 and not a 3 with respect to 7\n",
    "# 6. And doesn't scale to compare against the whole 0-9 set of digits\n",
    "# 7. This approach doesn't allow our model to LEARN from data and improve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) What is a list comprehension?  Create one now that selects odd numbers from a list and doubles them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Adding [5] to list as [10]\n",
      "1\n",
      "Adding [1] to list as [2]\n",
      "0\n",
      "3\n",
      "Adding [3] to list as [6]\n",
      "4\n",
      "[10, 2, 6] # List comprehension\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import random\n",
    "\n",
    "# Standard python list\n",
    "listnum = []\n",
    "randomlist = random.sample(range(0, 10), 5)\n",
    "for num in randomlist:\n",
    "    print(f'{num}')\n",
    "    if(num%2 == 1): # if odd\n",
    "        listnum.append(num * 2) # double it\n",
    "        print(f'Adding [{num}] to list as [{listnum[-1]}]')\n",
    "\n",
    "# List comprehension does all that in one line\n",
    "listcomprehension = [num * 2 for num in randomlist if num%2 ==1]\n",
    "print(f'{listcomprehension} # List comprehension')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What is a rank-3 tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank is the number of axes in a tensor \n",
    "# A rank 3 tensor is a 3D array of numbers\n",
    "# An images has a rank of 3 => (height, width, channels)\n",
    "# Grey scale images have 1 channel, while color images have 3 channels for RGB\n",
    "# A common image that handles transparency has 4 channels, RGB + alpha\n",
    "\n",
    "\n",
    "# Is this autopilot comment correct?\n",
    "# Rank 0 is a scalar\n",
    "# Rank 1 is a vector\n",
    "# Rank 2 is a matrix\n",
    "# Rank 3 is a 3D tensor\n",
    "# Rank 4 is a 4D tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What is the difference between tensor rank and shape? How do you get the rank from the shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank is the number of axes in a tensor\n",
    "# A stack of MNIST images has a rank of 3 => (height, width, channels)\n",
    "# A tensor shape is the size of each axis => the mnist_3.shape is \n",
    "# torch.Size([6131, 28, 28])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What are RMSE and L1 norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 norm is the sum of the absolute values of the elements in a tensor\n",
    "# Also known as the Manhattan distance\n",
    "\n",
    "# RMSE is Roof Mean Square Error is frequently used to measure the difference \n",
    "# between the predicted and actual values of a model\n",
    "# Also known as the Euclidean distance or L2 norm\n",
    "\n",
    "# The lower the value, the better the model is : 0 is perfect in principle\n",
    "\n",
    "# TODO : What is the difference between L1 and L2 norm?\n",
    "# Euclidean distance is usually preferred over Manhattan distance when there is\n",
    "# HIGH DIMENSIONALITY, because the Euclidean distance is more sensitive to\n",
    "# outliers in high dimensional space\n",
    "# Manhattan distance is usually preferred over Euclidean distance when there is\n",
    "# LOW DIMENSIONALITY, because the Manhattan distance is more sensitive to\n",
    "# outliers in low dimensional space\n",
    "# What does this mean lol?\n",
    "\n",
    "# ANSWER : Euclidean distance is the straight line distance between two points\n",
    "# Manhattan distance is the sum of the absolute differences between two points\n",
    "# Euclidean distance is the length of \"as the crow flies\" where as Manhattan\n",
    "# distance is the length of \"as the taxi drives\" transformed by roads and \n",
    "# traffic lights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can apply a calculation on thousands of numbers at once, many thousands of\n",
    "# times faster than a Python loop by using the native code in the Pytorch library\n",
    "# as opposed to pure Python math operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Create a 3x3 tensor array containing the numbers 1 to 9.  Double it.  Select the bottom right four numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) # 3x3 tensor the numbers 1 to 9\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12],\n",
      "        [14, 16, 18]]) # tensor doubled\n",
      "tensor([[ 8, 10, 12],\n",
      "        [14, 16, 18]]) # row 1 and beyond\n",
      "tensor([[ 4,  6],\n",
      "        [10, 12],\n",
      "        [16, 18]]) # column 1 and beyond\n",
      "tensor([[10, 12],\n",
      "        [16, 18]]) # bottom right 4 numbers\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.core import tensor\n",
    "# 3x3 tensor array containing the numbers 1 to 9\n",
    "tns = tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(f'{tns} # 3x3 tensor the numbers 1 to 9')\n",
    "\n",
    "# double all the number in the tensors\n",
    "tns = tns * 2\n",
    "print(f'{tns} # tensor doubled')\n",
    "print(f'{tns[1:,]} # row 1 and beyond')\n",
    "print(f'{tns[0:,1:]} # column 1 and beyond')\n",
    "# select the bottom right 4 numbers\n",
    "tns = tns[1:, 1:]\n",
    "print(f'{tns} # bottom right 4 numbers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) What is broadcasting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting is the ability to perform operations on tensors of different shapes\n",
    "# by automatically expanding the smaller tensor to match the shape of the larger\n",
    "# tensor\n",
    "# For example, you can add a scalar to a tensor, and the scalar will be added to\n",
    "# each element of the tensor\n",
    "# Or you can add a vector to a matrix, and the vector will be added to each row of\n",
    "# the matrix\n",
    "# Or you can add a matrix to a 3D tensor, and the matrix will be added to each\n",
    "# slice of the 3D tensor\n",
    "# Or you can add a 3D tensor to a 4D tensor, and the 3D tensor will be added to\n",
    "# each element of the 4D tensor\n",
    "# Broadcasting is a very powerful feature of Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Are metrics generally calculated using the training set or validation set? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics are generally calculated using the validation set\n",
    "# If using the training set, the model will be overfitting to the training set\n",
    "# and will not generalize well in production"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What is SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD is Stochastic Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Why does SGD use mini-batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD uses mini-batches because it maps better to the hardware of modern GPUs\n",
    "# which are optimized for parallel processing\n",
    "# And as a result will train faster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What are the seven steps in SGD for machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The seven steps in SGD for machine learning are:\n",
    "# 1) Initialize the weights (RANDOMLY for NEW model or add to PREVIOUS model weights for TRANSFER learning)\n",
    "# 2) Calculate predictions\n",
    "# 3) Calculate loss i.e. measure distance from prediction to expected result\n",
    "# 4) Calculate gradient i.e. approximation of direction and magnitude that parameter needs to change\n",
    "# 5) Step update the weights in the direction of the gradient\n",
    "# 6) Repeat from (2)\n",
    "# 7) Stop : either from limited resource or error metric is acceptable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) How do we initialize the weights in a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the weights in a model by:\n",
    "# 1) Randomly assigning weights to the model when we want to train from scratch\n",
    "# 2) Else if we are transfer learning, we add to the previous model weights and do nothing\n",
    "#   to the weights that are already trained, and update from there\n",
    "# We want to train from scratch when we want to build we need to solve a problem\n",
    "# specific to our data, many tabular models are trained from scratch\n",
    "# We want to transfer learn when there's existing knowledge that are already available\n",
    "# that we can build on top of, many computer vision models are transfer learned\n",
    "# because shape and color are universal concepts that have WIDE carry-over"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0203b3654eb8bc60da03d36108deed569263a68c1ed718ab77fdacb38634fa76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
